{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESG Active RL Portfolio Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from stable_baselines3 import DQN, DDPG\n",
    "\n",
    "from alphaQ.utils import download_ticker_data, train_test_split, plot_episodes, sharpe, save_to_s3, load_from_s3\n",
    "from alphaQ.env import PortfolioEnv\n",
    "from alphaQ.agent.features import FeatureExtractor\n",
    "from alphaQ.agent.callbacks import EvalCallback\n",
    "from alphaQ.agent.utils import AgentStrategy, load_model, display_attributes\n",
    "from alphaQ.eval import evalu8, evaluate_baselines\n",
    "\n",
    "import config\n",
    "import config as cfg\n",
    "from config import MODELS, MODEL_PARAMS\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rcParams = {\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'figure.figsize': (18, 9),\n",
    "    'legend.fontsize': 13,\n",
    "    'axes.labelsize': 14\n",
    "}\n",
    "plt.rcParams.update(rcParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment config\n",
    "EXP_NAME = \"esg_dqn_low_lr\"  # Experiment name\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "model = 'dqn'\n",
    "\n",
    "train_episodes = 50  # Num pre-training episodes (20 DDPG, 30 DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ticker and market data, split into train, validation and test sets\n",
    "esg_key = 'tradeGPT/prices/esg.pkl'\n",
    "market_key = 'tradeGPT/prices/market.pkl'  # SPY\n",
    "\n",
    "tickers = [\"MSFT\", \"NVDA\", \"GOOGL\", \"LLY\"]  # MSCI USA ESG Leaders Index (USD)\n",
    "tickers = [\"MSFT\", \"NVDA\", \"GOOGL\", \"LLY\"]  # MSCI USA ESG Leaders Index (USD)\n",
    "\n",
    "if False:\n",
    "    data = download_ticker_data(tickers, start=config.START, end=config.END, columns=['Open', 'High', 'Low', 'Close']).dropna()\n",
    "    save_to_s3(data, esg_key)\n",
    "    market = download_ticker_data('SPY', start=config.START, end=config.END, columns=['Adj Close']).loc[data.index]\n",
    "    save_to_s3(market, market_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_from_s3(esg_key)\n",
    "market = load_from_s3(market_key)\n",
    "\n",
    "train, val, test = train_test_split(data, train_years=12)\n",
    "market_train, market_val, market_test = train_test_split(market, train_years=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space_type = config.ACTION_SPACE[model]\n",
    "\n",
    "config.RENDER_ENV = False\n",
    "config.RENDER_FREQ = 2\n",
    "\n",
    "TICKERS = [\"MSFT\", \"NVDA\", \"GOOGL\", \"LLY\"]  # MSCI USA ESG Leaders Index (USD)\n",
    "# tickers = [\"\"]  # S&P Global Clean Energy Index (argue that this is down recently, we need a way to actively trade these stocks)\n",
    "\n",
    "# Train and val environments\n",
    "env = PortfolioEnv(\n",
    "    tickers=tickers,\n",
    "    prices=train,\n",
    "    market_prices=market,\n",
    "    window_length=config.WINDOW_LENGTH,\n",
    "    trading_cost=config.COMMISSION_RATE,\n",
    "    action_space_type=action_space_type,\n",
    "    render=config.RENDER_ENV,\n",
    ")\n",
    "val_env = PortfolioEnv(\n",
    "    tickers=tickers,\n",
    "    prices=val, \n",
    "    market_prices=market_val,\n",
    "    window_length=config.WINDOW_LENGTH,\n",
    "    trading_cost=config.COMMISSION_RATE,\n",
    "    action_space_type=action_space_type,\n",
    "    render=config.RENDER_ENV,\n",
    "    render_mode='val'\n",
    ")\n",
    "test_env = PortfolioEnv(\n",
    "    tickers=tickers,\n",
    "    prices=test, \n",
    "    market_prices=market_test,\n",
    "    window_length=config.WINDOW_LENGTH,\n",
    "    trading_cost=config.COMMISSION_RATE,\n",
    "    action_space_type=action_space_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up model args\n",
    "model_params = MODEL_PARAMS[model]\n",
    "\n",
    "# Set neural network parameters\n",
    "policy_kwargs = {\n",
    "    'features_extractor_class': FeatureExtractor,\n",
    "    'features_extractor_kwargs': {\n",
    "        'features_dim': 16 * model_params['multiplier'] * 4 + 5,\n",
    "        'multiplier': model_params['multiplier']\n",
    "    },\n",
    "    'net_arch': model_params['net_arch'],\n",
    "    'optimizer_kwargs': {\n",
    "#         'weight_decay': 5e-9,  # uncomment to use ridge regularisation\n",
    "    },\n",
    "}\n",
    "\n",
    "# load model hyperparameters\n",
    "model_kwargs = dict(model_params['hyperparams'])\n",
    "# add exploration params\n",
    "model_kwargs.update(model_params['exploration'])\n",
    "\n",
    "# set up action noise (for DDPG)\n",
    "if 'action_noise' in model_kwargs:\n",
    "    # determine dimension of action space\n",
    "    n_actions = env.action_space.shape[-1]\n",
    "    # extract noise sigma from params\n",
    "    sigma = model_kwargs.pop('noise_sigma')\n",
    "    model_kwargs['action_noise'] = config.ACTION_NOISE[model_kwargs['action_noise']](\n",
    "        mean=np.zeros(n_actions), \n",
    "        sigma= sigma * np.ones(n_actions)\n",
    "    )\n",
    "\n",
    "model_kwargs.get('action_noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping. Is kind of already implemented. I think we just cap at 20 episodes,\n",
    "# then say as a limitation, we could try training extremely long runs. Thing is, training is just hella unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train agent from scratch\n",
    "best_model_save_path = f'{config.SAVE_PATH}/{EXP_NAME}/best_model'\n",
    "episode_length = env.prices.shape[0] - config.WINDOW_LENGTH\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env=val_env, \n",
    "    n_eval_episodes=1,\n",
    "    eval_freq=episode_length,\n",
    "    log_path=config.LOG_PATH,\n",
    "    best_model_save_path=best_model_save_path,\n",
    "    verbose=config.CALLBACK_VERBOSE_LEVEL,\n",
    "    warn=False,\n",
    ")\n",
    "agent = MODELS[model](\n",
    "    env=env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=config.TRAIN_VERBOSE_LEVEL, \n",
    "    seed=config.RANDOM_SEED,\n",
    "    **model_kwargs,\n",
    ")\n",
    "\n",
    "agent.learn(total_timesteps=train_episodes*episode_length, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curves\n",
    "pd.DataFrame(env.record.episodes).plot()\n",
    "pd.DataFrame(val_env.record.episodes).plot()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20acc1d85ed4341021c93850c725098f352660f3df6a3b59dcdfe94746c44c08"
  },
  "kernelspec": {
   "display_name": "Python 3.7.17 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
